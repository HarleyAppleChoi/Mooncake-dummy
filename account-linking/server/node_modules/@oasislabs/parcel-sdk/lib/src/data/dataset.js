"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];
    result["default"] = mod;
    return result;
};
Object.defineProperty(exports, "__esModule", { value: true });
const oasis_std_1 = require("oasis-std");
const readable_stream_1 = require("readable-stream");
const dataset = __importStar(require("../service-clients/dataset"));
var dataset_1 = require("../service-clients/dataset");
exports.DatasetAccessRequested = dataset_1.AccessRequested;
exports.DatasetCipher = dataset_1.Cipher;
exports.DatasetCreated = dataset_1.DatasetCreated;
exports.DatasetDeactivated = dataset_1.DatasetDeactivated;
exports.DatasetDispatcherChanged = dataset_1.DispatcherChanged;
exports.DatasetError = dataset_1.Error;
exports.DatasetMetadata = dataset_1.Metadata;
exports.DatasetOwnerChanged = dataset_1.OwnerChanged;
exports.DatasetPolicyChanged = dataset_1.PolicyChanged;
const utils_1 = require("../utils");
const crypto_1 = require("./crypto");
// DatasetMetadata has a BigInt-typed `size` property. BigInt does not support JSON serialization by default.
// This addition lets us dump `size` in logs. It's not a great solution because it messes with the global
// prototype. This should go away soon with the new version of Parcel.
BigInt.prototype.toJSON = function () {
    this.toString();
};
/**
 * A dataset is a service that points to off-chain data.
 * This interface is intended for both dataset owners and consumers.
 */
class Dataset {
    constructor(client, pubState, config) {
        this.client = client;
        this.pubState = pubState;
        this.config = config;
        this.creationTimestamp = new Date(0);
        this.deactivationTimestamp = new Date(0);
        this.address = client.address;
        this.metadata = pubState.metadata;
        this.creator = pubState.creator;
        this.owner = pubState.owner;
        this.active = pubState.active;
        this.policy = pubState.policy;
    }
    /**
     * Connects to an existing Dataset service using the authority of the provided identity.
     * If `forceChainLookup` is given, fetches the info from the blockchain, skipping the
     * indexer. This is more costly but guaranteed to have the latest data.
     * WARNING - if `forceChainLookup` is used, the `creationTimestamp` and
     *           `deactivationTimestamp` will not be set on the returned object.
     * @returns a client to the newly-created Dataset that inherits its capabilities from
     *          the identity.
     */
    static connect(address, identity, config, forceChainLookup = false) {
        return __awaiter(this, void 0, void 0, function* () {
            const client = yield dataset.Dataset.connect(address, identity.proxy);
            function datasetFromChain(address, identity, config) {
                return __awaiter(this, void 0, void 0, function* () {
                    const pubState = yield client.getPublicState();
                    config.log.debug({ pubState }, `Retrieved public state for dataset ${address.hex} from the chain.`);
                    return new Dataset(client, pubState, config);
                });
            }
            if (forceChainLookup) {
                return datasetFromChain(address, identity, config);
            }
            let connectedDataset;
            try {
                const res = yield utils_1.queryIndex('dataset/getDatasetPublicState', address, config.indexerUrl, config.oasisGateway, config.tokenProvider, {
                    dataset: address.hex,
                }, config.log);
                const pubState = new dataset.PublicState({
                    creator: new oasis_std_1.Address(res.creator),
                    owner: new oasis_std_1.Address(res.owner),
                    metadata: new dataset.Metadata({
                        title: res.metadata.title,
                        dataUrl: res.metadata.dataUrl,
                        metadataUrl: res.metadata.metadataUrl,
                        size: BigInt(res.metadata.size),
                        rootHash: new Uint8Array(),
                    }),
                    active: res.active,
                    policy: res.policy.match(/^(0x)?0+$/) ? undefined : new oasis_std_1.Address(res.policy),
                });
                config.log.debug({ pubState }, `Retrieved public state for dataset ${address.hex} from the indexer.`);
                connectedDataset = new Dataset(client, pubState, config);
                // Assign out-of-band attributes.
                connectedDataset.creationTimestamp = new Date(res.creationTimestamp * 1000);
                connectedDataset.deactivationTimestamp = new Date(res.deactivationTimestamp * 1000);
            }
            catch (err) {
                config.log.info({ err }, `Failed to retrieve public state for dataset ${address.hex} from indexer. Querying the chain.`);
                connectedDataset = yield datasetFromChain(address, identity, config);
                // The chain does not conveniently expose the creation timestamp for the Dataset; it can only
                // be inferred by listening to (or replaying) the DatasetCreated event. The best we can do here
                // is guess the approximate time. Since the indexer doesn't know the Dataset but the chain does,
                // it is most likely that the dataset was created just a few seconds ago.
                if (err instanceof utils_1.UnindexedObjectError) {
                    connectedDataset.creationTimestamp = new Date();
                }
            }
            return connectedDataset;
        });
    }
    /**
     * Creates a new Dataset from un-encrypted data.
     * This will:
     * 1. encrypt the data using a new, random key
     * 2. upload the data to `storage` (if `undefined`, defers to `config.storages`)
     * 3. create a new Dataset service containing the pointer to data and its key
     * @returns a client to the newly-created Dataset
     */
    static upload(data, metadata, owner, config, opts, cipher = crypto_1.createDefaultCipher()) {
        return __awaiter(this, void 0, void 0, function* () {
            const { cipher: usedCipher, ciphertext } = crypto_1.encrypt(data, cipher);
            config.log.debug(`Encrypted data for a new dataset.`);
            return this.uploadRaw(usedCipher, ciphertext, metadata, owner, config, opts);
        });
    }
    /**
     * Like `upload` but from maybe-unencrypted data. If it's already encrypted, you'll want to
     * specify `encryptionKey` so that it can be sent to the Dataset service.
     * @returns a client to the newly-created Dataset
     */
    static uploadRaw(cipher, data, metadata, owner, config, opts) {
        var _a;
        return __awaiter(this, void 0, void 0, function* () {
            const backend = (_a = opts === null || opts === void 0 ? void 0 : opts.storage) !== null && _a !== void 0 ? _a : config.defaultUploadBackend;
            const { path: dataUrl, size } = yield backend.put(data);
            config.log.debug(`Uploaded data for a new dataset to ${dataUrl}.`);
            const datasetMetadata = new dataset.Metadata({
                title: metadata.title,
                metadataUrl: metadata.metadataUrl,
                size,
                dataUrl,
                rootHash: new Uint8Array(),
            });
            return this.createFromExistingData(cipher, datasetMetadata, owner, config, opts);
        });
    }
    /**
     * Creates a new Dataset service that points at pre-existing data.
     * For an encrypted dataset, you should `encryptionKey` so that the
     * service can grant access to the data.
     * @returns the newly-created Dataset
     */
    static createFromExistingData(cipher, metadata, owner, config, opts) {
        var _a, _b, _c, _d;
        return __awaiter(this, void 0, void 0, function* () {
            const creator = (_a = opts === null || opts === void 0 ? void 0 : opts.creator) !== null && _a !== void 0 ? _a : (yield config.getTokenIdentity());
            const deployConfig = {
                owner: owner.address,
                metadata,
                encryption: cipher,
                trustedDispatcher: config.dispatcherAddress,
                policy: (_b = opts === null || opts === void 0 ? void 0 : opts.policy) === null || _b === void 0 ? void 0 : _b.address,
            };
            config.log.trace({ deployConfig: Object.assign(Object.assign({}, deployConfig), { encryption: deployConfig.encryption.toString() }) }, `Deploying a new Dataset service.`);
            // Deploy the on-chain service.
            let innerDataset;
            try {
                innerDataset = yield dataset.Dataset.deploy(creator.proxy, deployConfig);
            }
            catch (err) {
                config.log.error({
                    err,
                    deployConfig: Object.assign(Object.assign({}, deployConfig), { encryption: deployConfig.encryption.toString() }),
                }, `Failed to deploy a Dataset service`);
                throw err;
            }
            // Create the wrapper object.
            let uploadedDataset;
            if ((_c = opts === null || opts === void 0 ? void 0 : opts.policy) === null || _c === void 0 ? void 0 : _c.address) {
                config.log.trace({ datasetAddress: innerDataset.address.hex }, 'Explicit policy provided; constructing local Dataset object without querying the chain');
                uploadedDataset = new Dataset(innerDataset, new dataset.PublicState({
                    creator: creator.address,
                    owner: owner.address,
                    metadata,
                    policy: (_d = opts === null || opts === void 0 ? void 0 : opts.policy) === null || _d === void 0 ? void 0 : _d.address,
                    active: true,
                }), config);
            }
            else {
                config.log.trace({ datasetAddress: innerDataset.address.hex }, 'No explicit policy provided for dataset; fetching data from indexer/chain to retrieve any implicit blanket policies.');
                try {
                    // Force chain lookup; the indexer might know about the dataset but not yet
                    // about the blanket policy (it learns about the two separately).
                    uploadedDataset = yield Dataset.connect(innerDataset.address, creator, config, true /*forceChainLookup*/);
                }
                catch (err) {
                    config.log.error({ address: innerDataset.address.hex, creator: creator.address.hex }, 'Failed to connect to the Dataset that was just created');
                    throw err;
                }
            }
            // Assign out-of-band attributes. On `deploy` this is set to the current
            // timestamp as an estimate of the true creation timestamp, since the
            // creation event may not have been propagated to the indexer yet.
            uploadedDataset.creationTimestamp = new Date();
            config.log.debug({
                dataset: {
                    address: uploadedDataset.address.hex,
                    owner: owner.address.hex,
                    creator: creator.address.hex,
                    url: metadata.dataUrl,
                },
            }, `Dataset deployed.`);
            return uploadedDataset;
        });
    }
    /**
     * Returns the dataset encryption key, if all policies are satisfied.
     * @throws if the Identity does not have permission to retrieve the key.
     */
    requestAccess() {
        return __awaiter(this, void 0, void 0, function* () {
            return this.client.requestAccess({ trustedRequester: undefined });
        });
    }
    /**
     * Returns the log of access requests to this dataset.
     * @throws if the identity does not have permission to read the access log
     */
    getAccessLog() {
        return __awaiter(this, void 0, void 0, function* () {
            try {
                const res = yield utils_1.queryIndex('dataset/getAccessLog', this.address, this.config.indexerUrl, this.config.oasisGateway, this.config.tokenProvider, {
                    dataset: this.address.hex,
                }, this.config.log);
                return Promise.all(res.log.map((accessLogEntry) => {
                    return {
                        identityAddress: new oasis_std_1.Address(accessLogEntry.identity),
                        timestamp: new Date(accessLogEntry.timestamp * 1000),
                        success: accessLogEntry.success,
                    };
                }));
            }
            catch (err) {
                this.config.log.warn({ err }, `Failed to fetch access log for dataset ${this.address.hex} from indexer. Returning empty log as fallback.`);
                return new Array();
            }
        });
    }
    /**
     * Get decrypted data from dataset.
     * This will:
     * 1. request access to the dataset's encryption key (unless given as `cipher`)
     * 2. fetch data from storage
     * 3. decrypt it
     */
    download(cipher) {
        const storage = this.config.storageBackendForPath(this.metadata.dataUrl);
        const ciphertext = storage.get(this.metadata.dataUrl);
        const plaintext = new readable_stream_1.PassThrough();
        ciphertext.on('error', plaintext.destroy.bind(plaintext));
        Promise.resolve(cipher !== null && cipher !== void 0 ? cipher : this.requestAccess())
            .then((cipher) => {
            crypto_1.decrypt(cipher, ciphertext)
                .on('error', plaintext.destroy.bind(plaintext))
                .pipe(plaintext);
        })
            .catch((err) => {
            this.config.log.error({ err }, `Failed to download or decrypt dataset ${this.address.hex} from ${this.metadata.dataUrl}.`);
            ciphertext.destroy(err);
        });
        return plaintext;
    }
    /**
     * Get decrypted data from dataset and write it to a local file.
     */
    downloadToPath(path, cipher) {
        return __awaiter(this, void 0, void 0, function* () {
            const data = this.download(cipher);
            return new Promise((resolve, reject) => {
                data.on('error', reject)
                    .pipe(require('fs').createWriteStream(path))
                    .on('error', reject)
                    .on('finish', resolve);
            });
        });
    }
    /**
     * Sets the policy of the Dataset service. Pass `null` to unset the policy.
     * @throws if the Identity does not have permission to modify the policy.
     */
    setPolicy(policy) {
        return __awaiter(this, void 0, void 0, function* () {
            yield this.client.setPolicy({ newPolicy: policy === null || policy === void 0 ? void 0 : policy.address });
            this.policy = policy === null || policy === void 0 ? void 0 : policy.address;
        });
    }
    /**
     * Sets the new owner of this dataset if the current owner is represented by
     * the connected Identity.
     */
    transferOwnership(newOwner) {
        return __awaiter(this, void 0, void 0, function* () {
            yield this.client.transferOwnership({ newOwner: newOwner.address });
            this.owner = newOwner.address;
        });
    }
    /**
     * Marks this Dataset as inactive. This will prevent future access to the data
     * and is equivalent to removing all policies.
     * This does not delete the physical copies of linked data, as it's possible that the
     * (encrypted) data has been cached by another storage cluster or compute node.
     */
    deactivate() {
        return __awaiter(this, void 0, void 0, function* () {
            yield this.client.deactivate();
            this.active = false;
            this.deactivationTimestamp = new Date();
        });
    }
    /** Human-readable information about the object's core properties */
    debugString() {
        var _a, _b;
        return __awaiter(this, void 0, void 0, function* () {
            return `Dataset${this.active ? '' : ' (DEACTIVATED)'} at ${this.address.hex}
  Title:   ${this.metadata.title}
  Creator: ${this.creator.hex}
  Owner:   ${this.owner.hex}
  URL:     ${this.metadata.dataUrl}
  Size:    ${this.metadata.size.toString()} bytes (${(Number(this.metadata.size) /
                1024 /
                1024).toFixed(1)} MB)
  Policy:  ${(_b = (_a = this.policy) === null || _a === void 0 ? void 0 : _a.hex) !== null && _b !== void 0 ? _b : 'none'}`;
        });
    }
}
exports.Dataset = Dataset;
//# sourceMappingURL=dataset.js.map